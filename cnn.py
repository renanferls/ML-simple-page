# -*- coding: utf-8 -*-
"""Maiz_clasificacion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Anh6uwtv7G2emCDQXa-RAsS5QQ_tz2x

## **EVALUACIÓN DE TÉCNICAS DE PARA CLASIFICAR MAIZ**
---

## **a) Lectura y preprocesamiento de datos (generador de imágenes)**
---
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import os

from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.neighbors import KNeighborsClassifier

# drive.mount('/content/drive')
# path = os.listdir('/content/drive/MyDrive/ML/')
classes = {
    "amarillo-cristalino": 0,
    "blanco": 1,
    "chulpi": 2,
    "chuncho": 3,
    "kculli": 4,
    "peruanita": 5,
    "piscorunto": 6,
}

# #Entrar en cada carpeta y descomprimir el archivo zip
# !unrar x "/content/drive/MyDrive/Dataset-maiz.rar" "/content/drive/MyDrive/Dataset-maiz/"

import cv2

# from google.colab.patches import cv2_imshow
X = []
Y = []
for cls in classes:
    pth = "/home/rekarenan/Desktop/maices/" + cls
    for j in os.listdir(pth):
        img = cv2.imread(pth + "/" + j)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (224, 224))
        # fd,hog_image=hog(img,visualize=True,multichannel=True)
        # fd=hog(img,multichannel=True)
        X.append(img)
        Y.append(classes[cls])

X = np.array(X)
Y = np.array(Y)
np.unique(Y)
pd.Series(Y).value_counts()

X.shape

X_updated = X.reshape(len(X), -1)
X_updated.shape
xtrain, xtest, ytrain, ytest = train_test_split(
    X_updated, Y, random_state=10, test_size=0.20
)
xtrain.shape, xtest.shape

print(xtrain.max(), xtrain.min())
print(xtest.max(), xtest.min())
xtrain = xtrain / 255
xtest = xtest / 255
print(xtrain.max(), xtrain.min())
print(xtest.max(), xtest.min())

from sklearn.decomposition import PCA

print(xtrain.shape, xtest.shape)

pca = PCA(0.98)
# pca_train = pca.fit_transform(xtrain)
# pca_test = pca.transform(xtest)
pca_train = xtrain
pca_test = xtest

"""## **b) Clasificador KNN**
---
"""

x_axis_k_points = []
f1_euclidean = []
accuracies_euclidean = []
conf_matrix_euclidean = []

knn_euclidean = KNeighborsClassifier(n_neighbors=8)
knn_euclidean.fit(pca_train, ytrain)

pred_labels_euclidean = knn_euclidean.predict(pca_test)

acc_euclidean = knn_euclidean.score(pca_test, ytest)
accuracies_euclidean.append(acc_euclidean)

conf_matrix_euclidean.append(metrics.confusion_matrix(ytest, pred_labels_euclidean))

f1_euclidean.append(metrics.f1_score(ytest, pred_labels_euclidean, average="micro"))
x_axis_k_points.append(8)

import pickle

pickle.dump(knn_euclidean, open("model.pkl", "wb"))

pickled_model = pickle.load(open("model.pkl", "rb"))
# pickled_model.predict(X_test)


"""##**c) Clasificador SVM**
---
"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import warnings

warnings.filterwarnings("ignore")
f1_sv = []
accuracies_sv = []
conf_matrix_sv = []
accuracies_svm = []
lg = LogisticRegression(C=0.1)
lg.fit(pca_train, ytrain)
sv = SVC()
sv.fit(pca_train, ytrain)
pred_labels_sv = sv.predict(pca_test)

acc_sv = sv.score(pca_test, ytest)
accuracies_sv.append(acc_sv)

conf_matrix_sv.append(metrics.confusion_matrix(ytest, pred_labels_sv))

f1_sv.append(metrics.f1_score(ytest, pred_labels_sv, average="micro"))

import pickle

pickle.dump(sv, open("model2.pkl", "wb"))

pickled_model2 = pickle.load(open("model2.pkl", "rb"))

pred_labels_sv = pickled_model2.predict(pca_test)

acc_sv = pickled_model2.score(pca_test, ytest)
accuracies_sv.append(acc_sv)

conf_matrix_sv.append(metrics.confusion_matrix(ytest, pred_labels_sv))

f1_sv.append(metrics.f1_score(ytest, pred_labels_sv, average="micro"))

"""##**c) Comparación con ML**
---

##**KNN**
---
"""

from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
)
print("Y TEST", ytest)
print("EUCLIDEAN", pred_labels_euclidean)
print("classes", classes)

cr = classification_report(ytest, pred_labels_euclidean, target_names=classes)
cm = confusion_matrix(ytest, pred_labels_euclidean)

import numpy as np
import seaborn as sns
from sklearn.metrics import classification_report
import pandas as pd

clf_report = classification_report(
    ytest, pred_labels_euclidean, target_names=classes, output_dict=True
)

sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)

from sklearn import metrics

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
cm_display.plot()
plt.show()

"""##**SVM**
---
"""

from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
)

cr = classification_report(ytest, pred_labels_sv, target_names=classes)
print(cr)
cm2 = confusion_matrix(ytest, pred_labels_sv)
print(cm2)

import numpy as np
import seaborn as sns
from sklearn.metrics import classification_report
import pandas as pd

clf_report = classification_report(
    ytest, pred_labels_sv, target_names=classes, output_dict=True
)

sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)

from sklearn import metrics

cm_display = metrics.ConfusionMatrixDisplay(
    confusion_matrix=cm2, display_labels=classes
)
cm_display.plot()
plt.show()

print("Training Score:", lg.score(pca_train, ytrain))
print("Testing Score:", lg.score(pca_test, ytest))
print("Training Score:", sv.score(pca_train, ytrain))
print("Testing Score:", sv.score(pca_test, ytest))
pred = sv.predict(pca_test)
np.where(ytest != pred)
pred[36]
ytest[36]

"""##**d) Predicciones con ML**
---
"""

# Variedades
variedades = [
    "amarillo-cristalino",
    "blanco",
    "chulpi",
    "chuncho",
    "kculli",
    "peruanita",
    "piscorunto",
]

# Predicción knn euclidean
for v in variedades:
    plt.figure(figsize=(12, 8))
    p = os.listdir("/content/drive/MyDrive/Dataset-maiz/" + v + "/")
    c = 1
    for i in os.listdir("/content/drive/MyDrive/Dataset-maiz/" + v + "/")[:16]:
        plt.subplot(4, 4, c)

        img = cv2.imread("/content/drive/MyDrive/Dataset-maiz/" + v + "/" + i)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img1 = cv2.resize(img, (224, 224))
        img1 = img1.reshape(1, -1) / 255
        p = pickled_model.predict(img1)
        plt.title(variedades[p[0]])

        plt.imshow(img, cmap="gray")

        plt.axis("off")
        c += 1

# Predicción knn manhattan
for v in variedades:
    plt.figure(figsize=(12, 8))
    p = os.listdir("/content/drive/MyDrive/aves/" + v + "/")
    c = 1
    for i in os.listdir("/content/drive/MyDrive/aves/" + v + "/")[:16]:
        plt.subplot(4, 4, c)

        img = cv2.imread("/content/drive/MyDrive/aves/" + v + "/" + i)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img1 = cv2.resize(img, (200, 200))
        img1 = img1.reshape(1, -1) / 255
        p = knn_manhattan.predict(img1)
        plt.title(variedades[p[0]])

        plt.imshow(img, cmap="gray")

        plt.axis("off")
        c += 1

# Predicción svm
for v in variedades:
    plt.figure(figsize=(12, 8))
    p = os.listdir("/content/drive/MyDrive/Dataset-maiz/" + v + "/")
    c = 1
    for i in os.listdir("/content/drive/MyDrive/Dataset-maiz/" + v + "/")[:16]:
        plt.subplot(4, 4, c)

        img = cv2.imread("/content/drive/MyDrive/Dataset-maiz/" + v + "/" + i)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img1 = cv2.resize(img, (224, 224))
        img1 = img1.reshape(1, -1) / 255
        p = pickled_model2.predict(img1)
        plt.title(variedades[p[0]])

        plt.imshow(img, cmap="gray")

        plt.axis("off")
        c += 1

"""## **e) Clasificador CNN**
---

## **f) Clasificación con CNN preentrenada**
---
"""

from tensorflow.keras.layers import (
    Input,
    Lambda,
    Dense,
    Flatten,
    Dropout,
    Conv2D,
    MaxPooling2D,
)
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt

# Redimensionar el tamaño de todas las imágenes
IMAGE_SIZE = (224, 224)
path = "/content/drive/MyDrive/Dataset-maiz"
data = []
c = 0
for folder in os.listdir(path):
    sub_path = path + "/" + folder
    for folder2 in os.listdir(sub_path):
        sub_path2 = sub_path + "/" + folder2
        img_arr = cv2.imread(sub_path2)
        try:
            img_arr = cv2.resize(img_arr, IMAGE_SIZE)
            data.append(img_arr)
        except:
            c += 1
            continue
print("Number of images skipped= ", c)

# Conversitar a array y normalizar
x = np.array(data)

x = x / 255.0

# Aumento de datos con ImageDataGenerator
datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=30,
    width_shift_range=0.25,
    height_shift_range=0.25,
    shear_range=15,
    zoom_range=[0.5, 1.5],
)
dataset = datagen.flow_from_directory(
    path, target_size=IMAGE_SIZE, batch_size=32, shuffle=True
)
# class_mode = 'sparse')

dataset.class_indices
y = dataset.classes
y.shape

# Separar los datos de entrenamiento y prueba
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
# x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2)

# Redimensionar
x_train.shape, y_train.shape
x_test.shape, y_test.shape

import tensorflow as tf
import tensorflow_hub as hub

# Desargar el modelo
url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
mobilenetv2 = hub.KerasLayer(url, input_shape=(224, 224, 3))

# Congelar el modelo descargado
mobilenetv2.trainable = False

model = tf.keras.Sequential(
    [mobilenetv2, tf.keras.layers.Dense(7, activation="softmax")]
)

model.summary()
# Compilar el modelo
model.compile(
    optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]
)

# Entrenar el modelo
history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=30)

from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model

# Guardar modelo
model.save("cnn1.h5")

# Cargar modelo
model3 = tf.keras.models.load_model(
    ("cnn1.h5"), custom_objects={"KerasLayer": hub.KerasLayer}
)

# Guardar pesos
model.save_weights("cnn1_weights.h5")

# Cargar pesos
model3_weights = model.load_weights("cnn1_weights.h5")

"""## **g) Clasificador CNN propia**
---
"""

import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation
from tensorflow.keras.layers import Convolution2D, MaxPooling2D
import numpy as np
import matplotlib.pyplot as plt

cnn = Sequential()
cnn.add(
    Convolution2D(
        32, (3, 3), padding="same", input_shape=(224, 224, 3), activation="relu"
    )
)
cnn.add(MaxPooling2D(pool_size=(2, 2)))
cnn.add(Convolution2D(32, (2, 2), padding="same"))
cnn.add(MaxPooling2D(pool_size=(2, 2)))
cnn.add(Convolution2D(64, (2, 2), padding="same"))
cnn.add(MaxPooling2D(pool_size=(2, 2)))
cnn.add(Convolution2D(64, (2, 2), padding="same"))
cnn.add(MaxPooling2D(pool_size=(2, 2)))
cnn.add(Flatten())
cnn.add(Dense(256, activation="relu"))
cnn.add(Dense(128, activation="relu"))
cnn.add(Dropout(0.5))
cnn.add(Dense(7, activation="softmax"))

cnn.compile(
    optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]
)

cnn.summary()

# Entrenar el modelo
history = cnn.fit(
    x_train, y_train, validation_data=(x_test, y_test), epochs=30, shuffle=True
)

from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model

# Guardar modelo
model.save("cnn2.h5")

# Cargar modelo
model3 = tf.keras.models.load_model(
    ("cnn2.h5"), custom_objects={"KerasLayer": hub.KerasLayer}
)

# Guardar pesos
model.save_weights("cnn2_weights.h5")

# Cargar pesos
model3_weights = model.load_weights("cnn2_weights.h5")

"""## **h) Evaluación de accuracy-lost**
---

## **Cnn preentrenada**
---
"""

# Graficas de precisión
acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]

loss = history.history["loss"]
val_loss = history.history["val_loss"]

rango_epocas = range(30)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(rango_epocas, acc, label="Precisión Entrenamiento")
plt.plot(rango_epocas, val_acc, label="Precisión Pruebas")
plt.legend(loc="lower right")
plt.title("Precisión de entrenamiento y pruebas")

plt.subplot(1, 2, 2)
plt.plot(rango_epocas, loss, label="Pérdida de entrenamiento")
plt.plot(rango_epocas, val_loss, label="Pérdida de pruebas")
plt.legend(loc="upper right")
plt.title("Pérdida de entrenamiento y pruebas")
plt.savefig("accuracy_cnn1.png")
plt.show()

"""## **Cnn propia**
---
"""

# Graficas de precisión
acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]

loss = history.history["loss"]
val_loss = history.history["val_loss"]

rango_epocas = range(30)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(rango_epocas, acc, label="Precisión Entrenamiento")
plt.plot(rango_epocas, val_acc, label="Precisión Pruebas")
plt.legend(loc="lower right")
plt.title("Precisión de entrenamiento y pruebas")

plt.subplot(1, 2, 2)
plt.plot(rango_epocas, loss, label="Pérdida de entrenamiento")
plt.plot(rango_epocas, val_loss, label="Pérdida de pruebas")
plt.legend(loc="upper right")
plt.title("Pérdida de entrenamiento y pruebas")
plt.show()

"""## **i) Predicciones con CNN**
---
"""

import numpy as np
from tensorflow.keras.utils import load_img, img_to_array
from keras.models import load_model

datos = os.listdir("/content/drive/MyDrive/Dataset-maiz/")
for i in datos:
    imagen = os.listdir("/content/drive/MyDrive/Dataset-maiz/" + "/" + i)
    for w in range(3):
        path = "/content/drive/MyDrive/Dataset-maiz/" + "/" + i + "/" + imagen[w]
        x = load_img(path, target_size=(224, 224))
        y = img_to_array(x)
        y = np.expand_dims(y, axis=0)
        array = model.predict(y)
        print()
        plt.imshow(x)
        plt.show()
        print(f"Predición: {datos[np.argmax(array)]}")
        print(f"Real: {i}")
        print("--------------------------------------------------")

import numpy as np
from tensorflow.keras.utils import load_img, img_to_array
from keras.models import load_model

datos = os.listdir("/content/drive/MyDrive/Dataset-maiz/")
for i in datos:
    imagen = os.listdir("/content/drive/MyDrive/Dataset-maiz/" + "/" + i)
    for w in range(3):
        path = "/content/drive/MyDrive/Dataset-maiz/" + "/" + i + "/" + imagen[w]
        x = load_img(path, target_size=(224, 224))
        y = img_to_array(x)
        y = np.expand_dims(y, axis=0)
        array = cnn.predict(y)
        print()
        plt.imshow(x)
        plt.show()
        print(f"Predición: {datos[np.argmax(array)]}")
        print(f"Real: {i}")
        print("--------------------------------------------------")

"""## **j) Evaluación de métricas de desempeño con CNN**
---

## **CNN preentrenada**
---
"""

y_test_pred = model.predict(x_test)
y_test_pred = np.argmax(y_test_pred, axis=1)
cm3 = confusion_matrix(y_test_pred, y_test)

import numpy as np
import seaborn as sns
from sklearn.metrics import classification_report
import pandas as pd

clf_report = classification_report(
    y_test_pred, y_test, target_names=classes, output_dict=True
)

sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)

from sklearn import metrics

cm_display = metrics.ConfusionMatrixDisplay(
    confusion_matrix=cm3, display_labels=classes
)
cm_display.plot()
plt.show()

"""## **CNN propia**
---
"""

y_test_pred = cnn.predict(x_test)
y_test_pred = np.argmax(y_test_pred, axis=1)
cm4 = confusion_matrix(y_test_pred, y_test)

import numpy as np
import seaborn as sns
from sklearn.metrics import classification_report
import pandas as pd

clf_report = classification_report(
    y_test_pred, y_test, target_names=classes, output_dict=True
)

sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)

from sklearn import metrics

cm_display = metrics.ConfusionMatrixDisplay(
    confusion_matrix=cm4, display_labels=classes
)
cm_display.plot()
plt.show()

print("HOLA AMIGOS")
